{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Descision tree model\n",
        "\n"
      ],
      "metadata": {
        "id": "Qe6WifBU9BXg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8LLNzFZ3hMU",
        "outputId": "902d55da-7813-4c51-d54b-5dc5a6ced8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[502  28]\n",
            " [ 44 346]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93       530\n",
            "           1       0.93      0.89      0.91       390\n",
            "\n",
            "    accuracy                           0.92       920\n",
            "   macro avg       0.92      0.92      0.92       920\n",
            "weighted avg       0.92      0.92      0.92       920\n",
            "\n",
            "Accuracy = 0.9217391304347826\n"
          ]
        }
      ],
      "source": [
        "#Loading the libraries needed\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Loading the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/spambase.csv')\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Splitting the dataset into training and testing sets. Test size =0.2, random state =42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a Decision Tree classifier object\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Training the Decision Tree classifier\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the classes of testing data\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "# Evaluating the performance of the Decision Tree classifier\n",
        "accuracy = tree.score(X_test, y_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy =\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K - Nearest Neighbour model"
      ],
      "metadata": {
        "id": "t3tJjR1B9Xwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the libraries needed\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Loading the spambase dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/spambase.csv\")\n",
        "\n",
        "# Split data into features and target variables\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Splitting the dataset into training and testing sets. test size =0.2, random_state =42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a KNN classifier object\n",
        "k = 5\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Training the KNN classifier\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the classes of testing data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluating the performance of the KNN classifier\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy =\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-HT12bN3jlg",
        "outputId": "157ff6ba-4c59-48b6-b511-8a67de7c5ad7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[516  14]\n",
            " [ 82 308]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       530\n",
            "           1       0.96      0.79      0.87       390\n",
            "\n",
            "    accuracy                           0.90       920\n",
            "   macro avg       0.91      0.88      0.89       920\n",
            "weighted avg       0.90      0.90      0.89       920\n",
            "\n",
            "Accuracy = 0.8956521739130435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changes have been made to the model to improve accuracy:\n",
        "\n",
        "1. Applied feature selection using SelectKBest and f_classif.\n",
        "2. Applied feature scaling using StandardScaler.\n",
        "3. Changed the value of k to 10.\n",
        "4. Used the distance weights and Manhattan metric."
      ],
      "metadata": {
        "id": "n5C_r9AAM3rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the libraries needed\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Loading the spambase dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/spambase.csv\")\n",
        "\n",
        "# Split data into features and target variables\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Feature Selection\n",
        "selector = SelectKBest(score_func=f_classif, k=20)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Scaling the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_new)\n",
        "\n",
        "# Splitting the dataset into training and testing sets. test size =0.2, random_state =42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a KNN classifier object\n",
        "k = 10\n",
        "knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='manhattan')\n",
        "\n",
        "# Training the KNN classifier\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the classes of testing data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluating the performance of the KNN classifier\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy =\", accuracy)\n"
      ],
      "metadata": {
        "id": "MfdLpZWLMYsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Futher changes being applied to the KNN Model\n",
        "\n",
        "We can futher improve the accuracy if the KNN model by tuning it's hyper parameters. The following changes have been done to improve it's accuracy.\n",
        "\n",
        "  *   Optimize the k value\n",
        "  *   Optimizing the weight parameter\n",
        "  *   optimizing the distance metric\n",
        "\n"
      ],
      "metadata": {
        "id": "ktgpDAqyN7az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the libraries needed\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Loading the spambase dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/spambase.csv\")\n",
        "\n",
        "# Split data into features and target variables\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Feature Selection\n",
        "selector = SelectKBest(score_func=f_classif, k=20)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Scaling the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_new)\n",
        "\n",
        "# Splitting the dataset into training and testing sets. test size =0.2, random_state =42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a KNN classifier object\n",
        "k = 10\n",
        "knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='manhattan')\n",
        "\n",
        "# Training the KNN classifier\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the classes of testing data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluating the performance of the KNN classifier\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy =\", accuracy)\n",
        "\n",
        "# Tuning the hyperparameters\n",
        "# In order to improve the performance of the KNN classifier, we can tune its hyperparameters.\n",
        "\n",
        "# 1. Optimize the value of k\n",
        "k_values = list(range(1, 31))\n",
        "accuracies = []\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='manhattan')\n",
        "    knn.fit(X_train, y_train)\n",
        "    accuracy = knn.score(X_test, y_test)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "best_k = k_values[accuracies.index(max(accuracies))]\n",
        "print(\"The best value of k is\", best_k)\n",
        "\n",
        "# 2. Optimize the weight parameter\n",
        "weights = ['uniform', 'distance']\n",
        "accuracies = []\n",
        "for weight in weights:\n",
        "    knn = KNeighborsClassifier(n_neighbors=best_k, weights=weight, metric='manhattan')\n",
        "    knn.fit(X_train, y_train)\n",
        "    accuracy = knn.score(X_test, y_test)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "best_weight = weights[accuracies.index(max(accuracies))]\n",
        "print(\"The best weight parameter is\", best_weight)\n",
        "\n",
        "# 3. Optimize the distance metric\n",
        "metrics = ['euclidean', 'manhattan', 'minkowski']\n",
        "accuracies = []\n",
        "for metric in metrics:\n",
        "    knn = KNeighborsClassifier(n_neighbors=best_k, weights=best_weight, metric=metric)\n",
        "    knn.fit(X_train, y_train)\n",
        "    accuracy = knn.score(X_test, y_test)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "best_metric = metrics[accuracies.index(max(accuracies))]\n",
        "print(\"The best distance metric is\", best_metric)\n",
        "\n",
        "# Final evaluation of the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k, weights=best_weight, metric=best_metric)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy =\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo0avzx7NtTP",
        "outputId": "b331bf78-6460-42a5-f0f1-51f9a33b02c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[516  14]\n",
            " [ 82 308]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       530\n",
            "           1       0.96      0.79      0.87       390\n",
            "\n",
            "    accuracy                           0.90       920\n",
            "   macro avg       0.91      0.88      0.89       920\n",
            "weighted avg       0.90      0.90      0.89       920\n",
            "\n",
            "Accuracy = 0.8956521739130435\n",
            "The best value of k is 4\n",
            "The best weight parameter is distance\n",
            "The best distance metric is euclidean\n",
            "[[508  22]\n",
            " [ 65 325]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       530\n",
            "           1       0.94      0.83      0.88       390\n",
            "\n",
            "    accuracy                           0.91       920\n",
            "   macro avg       0.91      0.90      0.90       920\n",
            "weighted avg       0.91      0.91      0.90       920\n",
            "\n",
            "Accuracy = 0.9054347826086957\n"
          ]
        }
      ]
    }
  ]
}